{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting\n",
    "import pandas as pd # data manipulation and analysis\n",
    "import numpy as np # numerical computation\n",
    "import pickle\n",
    "\n",
    "import scipy\n",
    "from scipy.interpolate import spline\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import random\n",
    "import math\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pandas import DataFrame\n",
    "from pandas import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data from pickled files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = open(\"partitioned_features.pickle\",\"rb\")\n",
    "feat_all = pickle.load(f0)\n",
    "f0.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"partitioned_features_defective.pickle\",\"rb\")\n",
    "feat_defective = pickle.load(f1)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open(\"partitioned_features_good.pickle\",\"rb\")\n",
    "feat_good = pickle.load(f2)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality check 1 - check if all data in good is labeled w/ 0 and all data w/ defective is labeled w/ 1\n",
    "\n",
    "They passed the test :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in feat_defective:\n",
    "    for pt in test:\n",
    "        label = pt[-2]\n",
    "        if label==0:\n",
    "            print(\"Error\")\n",
    "            print(pt)\n",
    "        elif label!=1:\n",
    "            print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in feat_good:\n",
    "    for pt in test:\n",
    "        label = pt[-2]\n",
    "        if label==1:\n",
    "            print(\"Error\")\n",
    "            print(pt)\n",
    "        elif label!=0:\n",
    "            print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate all the means and statndard deviation\n",
    "\n",
    "The methods below take as input a list of features - this is the data, normalised and chopped. The output is some feature of the time series, for instance it could be the mean, the standard deviation, the max, the min, the norm gradient mean etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfeat_all_means = the_means(feat_all)\\nfeat_defective_means = the_means(feat_defective)\\nfeat_good_means = the_means(feat_good)\\n\\nfeat_all_stds = the_stds(feat_all)\\nfeat_defective_stds = the_means(feat_defective)\\nfeat_good_stds = the_means(feat_good)\\n\\nfeat_all_max = the_max(feat_all)\\nfeat_defective_max = the_max(feat_defective)\\nfeat_good_max = the_max(feat_good)\\n\\nfeat_all_min = the_min(feat_all)\\nfeat_defective_min = the_min(feat_defective)\\nfeat_good_min = the_min(feat_defective)'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def the_means(feature_list):\n",
    "    feat_means = []\n",
    "    for i in feature_list:\n",
    "        transposed = np.transpose(i)\n",
    "        means = []\n",
    "        for j in transposed:\n",
    "            means.append(np.mean(j))\n",
    "        feat_means.append(means)\n",
    "    return feat_means\n",
    "\n",
    "def the_stds(feature_list):\n",
    "    feat_stds = []\n",
    "    for i in feature_list:\n",
    "        transposed = np.transpose(i)\n",
    "        stds = []\n",
    "        for j in transposed:\n",
    "            stds.append(np.std(j))\n",
    "        feat_stds.append(stds)\n",
    "    return feat_stds\n",
    "\n",
    "def the_max(feature_list):\n",
    "    feat_max = []\n",
    "    for i in feature_list:\n",
    "        transposed = np.transpose(i)\n",
    "        maxes = []\n",
    "        for j in transposed:\n",
    "            maxes.append(max(j))\n",
    "        feat_max.append(maxes)\n",
    "    return feat_max\n",
    "\n",
    "def the_min(feature_list):\n",
    "    feat_min = []\n",
    "    for i in feature_list:\n",
    "        transposed = np.transpose(i)\n",
    "        mins1 = []\n",
    "        for j in transposed:\n",
    "            mins1.append(min(j))\n",
    "        feat_min.append(mins1)\n",
    "    return feat_min\n",
    "        \n",
    "def get_gradient(feature_list):# returns the gradient of everything\n",
    "    feat_grad = []\n",
    "    for i in feature_list:\n",
    "        transposed = np.transpose(i)\n",
    "        # find the gradient at each point\n",
    "        gradients = []\n",
    "        for j in range(len(transposed)):\n",
    "            grad_feat = []\n",
    "            for k in range(len(transposed[j])):\n",
    "                if k>=1:\n",
    "                    grad_feat.append(transposed[j][k]-transposed[j][k-1])\n",
    "            gradients.append(grad_feat)\n",
    "        feat_grad.append(np.transpose(gradients))\n",
    "    return feat_grad\n",
    "        \n",
    "def non_zero_grad_mean45(feature_list):# 2d\n",
    "    feature_grad = get_gradient(feature_list)\n",
    "    non_zero_grad_means = []\n",
    "    for i in feature_grad:\n",
    "        transposed = np.transpose(i)\n",
    "        non_zero_grad = [[],[]]\n",
    "        for j in [4,5]:\n",
    "            for k in range(len(transposed[j])):\n",
    "                if transposed[j][k]!=0:\n",
    "                    non_zero_grad[j-4].append(transposed[j][k])\n",
    "        a0 = np.mean([abs(i) for i in non_zero_grad[0]])\n",
    "        a1 = np.mean([abs(i) for i in non_zero_grad[0]])\n",
    "        non_zero_grad_means.append([a0,a1])\n",
    "    return non_zero_grad_means\n",
    "\n",
    "def gradient_norm_mean(feature_list):\n",
    "    feat_grad = get_gradient(feature_list)\n",
    "        \n",
    "    # we want a gradient (absolute value) mean as a feature\n",
    "    feat_grad = map(abs,feat_grad)\n",
    "    gradient_mean = the_means(feat_grad)\n",
    "    \n",
    "    return gradient_mean\n",
    "\n",
    "def double_derivative_norm_mean(feature_list):# 10 D\n",
    "    double_derivative = get_gradient(get_gradient(feature_list))\n",
    "    \n",
    "    # we want the absolute value mean of the double derivative\n",
    "    double_derivative = map(abs,double_derivative)\n",
    "    double_derivative_mean = the_means(double_derivative)\n",
    "    \n",
    "    return double_derivative_mean\n",
    "\n",
    "\n",
    "\n",
    "# noticed that features 4, 5 and 6 are often 50 for many data points in a row, in other\n",
    "# words the gradient is 0 quite alot. We therefore add two new features which are \n",
    "# 1) the number of data points where the gradient is 0 divided by the number of times the gradient is zero\n",
    "# we do this for numbers 4, 5 and 6\n",
    "def grad_new_features(feature_list):\n",
    "    feature_grad = get_gradient(feature_list)\n",
    "    new_features_list = []\n",
    "    for i in feature_grad:\n",
    "        transposed = np.transpose(i)\n",
    "        new_feature = []\n",
    "        for j in [4,5,6]:\n",
    "            count=0\n",
    "            for k in range(len(transposed[j])):\n",
    "                if transposed[j][k]==0: count+=1\n",
    "            try: new_feature.append(count/len(transposed[j]))\n",
    "            except ZeroDivisionError: new_feature.append(0)\n",
    "        new_features_list.append(new_feature)\n",
    "    return new_features_list\n",
    "        \n",
    "# returns feature list of how many times the gradient changes sign\n",
    "def turns(feature_list):\n",
    "    feature_grad = get_gradient(feature_list)\n",
    "    changes_sign_list = []\n",
    "    for i in feature_grad:\n",
    "        transposed = np.transpose(i)\n",
    "        changes_sign = []\n",
    "        for j in range(len(transposed)):\n",
    "            count=0\n",
    "            for k in range(1,len(transposed[j])):\n",
    "                if (transposed[j][k]>0 and transposed[j][k-1]<=0) or (transposed[j][k]<=0 and transposed[j][k]>0):\n",
    "                    count+=1\n",
    "            try: changes_sign.append(count/len(transposed[j]))\n",
    "            except ZeroDivisionError: changes_sign.append(0)\n",
    "        changes_sign_list.append(changes_sign)\n",
    "    return changes_sign_list\n",
    "\n",
    "\n",
    "#feat_all_grad_means = gradient_mean(feat_all)\n",
    "\n",
    "#feat_all_means = the_means(feat_all)\n",
    "\n",
    "#new_features = grad_new_features(feat_all)\n",
    "#dd = double_derivative_norm_mean(feat_all)\n",
    "#turns_all = turns(feat_all)\n",
    "\n",
    "\"\"\"\n",
    "feat_all_means = the_means(feat_all)\n",
    "feat_defective_means = the_means(feat_defective)\n",
    "feat_good_means = the_means(feat_good)\n",
    "\n",
    "feat_all_stds = the_stds(feat_all)\n",
    "feat_defective_stds = the_means(feat_defective)\n",
    "feat_good_stds = the_means(feat_good)\n",
    "\n",
    "feat_all_max = the_max(feat_all)\n",
    "feat_defective_max = the_max(feat_defective)\n",
    "feat_good_max = the_max(feat_good)\n",
    "\n",
    "feat_all_min = the_min(feat_all)\n",
    "feat_defective_min = the_min(feat_defective)\n",
    "feat_good_min = the_min(feat_defective)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We do something similar using ARIMA, we fit the data series with model (1,1,0) because it's fast. This works only for 1,4,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_arima_coefs(feature_list):\n",
    "    feat_arima = []\n",
    "    # first 1\n",
    "    for i in feature_list:\n",
    "        transposed = np.transpose(i)\n",
    "        series = transposed[1]\n",
    "        model = ARIMA(series, order=(1,1,0))\n",
    "        model_fit = model.fit(disp=0)\n",
    "        \n",
    "        params1 = model_fit.params[:]\n",
    "        \n",
    "        series = transposed[4]\n",
    "        model = ARIMA(series, order=(1,1,0))\n",
    "        model_fit = model.fit(disp=0)\n",
    "        \n",
    "        params4 = model_fit.params[:]\n",
    "        \n",
    "        serise = transposed[6]\n",
    "        model = ARIMA(series, order=(1,1,0))\n",
    "        model_fit = model.fit(disp=0)\n",
    "        \n",
    "        params6 = model_fit.params[:]\n",
    "        \n",
    "        feat_arima.append(list(params1)+list(params4)+list(params6))\n",
    "        \n",
    "    return feat_arima\n",
    "        \n",
    "        \n",
    "#a = feat_arima_coefs(time_series_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function takes viet's normalised (or not normalized) time series list and returns a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import viet's time series\n",
    "time_series_x = np.load('data_lstm/X_raw.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_map(time_series,pickle_name=\"time_series_features.pickle\",pickle=True):\n",
    "    # means\n",
    "    feat_means = the_means(time_series)# 10 D\n",
    "    # stds\n",
    "    feat_stds = the_stds(time_series)# 10 D\n",
    "    # maxes\n",
    "    feat_max = the_max(time_series)# 10 D\n",
    "    # min\n",
    "    feat_min = the_min(time_series)# 10 D\n",
    "    # gradient mean\n",
    "    feat_grad = gradient_norm_mean(time_series)# 10 D\n",
    "    # new features from 4,5,6\n",
    "    new_feat1 = grad_new_features(time_series)# 3 D\n",
    "    # non zero grad 4,5\n",
    "    non_zero_grad = non_zero_grad_mean45(time_series)# 2 D\n",
    "    # the double derivative mean\n",
    "    feat_dd = double_derivative_norm_mean(time_series)# 10 D\n",
    "    # the number of times the gradient changes sign\n",
    "    feat_changes_sign = turns(time_series)# 10 D\n",
    "    \n",
    "    # the arima stuff\n",
    "    feat_arima = feat_arima_coefs(time_series)\n",
    "    \n",
    "    big_features_list = [feat_means,feat_stds,feat_max,feat_min,feat_grad,new_feat1,\n",
    "                         non_zero_grad,feat_dd,feat_changes_sign,feat_arima]\n",
    "    for i in big_features_list:\n",
    "        try: print(len(i))\n",
    "        except: print(i)\n",
    "    #input()\n",
    "    ###\n",
    "    \n",
    "    # first check that they are all the same length\n",
    "    l = len(feat_means)\n",
    "    for i in big_features_list:\n",
    "        if len(i)!=l: raise Exception(\"features lists are not the same size, they should be\")\n",
    "        \n",
    "    complete_features_list = big_features_list[0]\n",
    "    for j in range(1,len(big_features_list)):\n",
    "        for k in range(len(big_features_list[0])):\n",
    "            complete_features_list[k] = complete_features_list[k]+big_features_list[j][k]\n",
    "    \n",
    "    #for j in big_features_list:\n",
    "     #   if j==feat_means: complete_features_list=[j]\n",
    "      #  else:\n",
    "       #     for k in range(l):\n",
    "        #        complete_features_list[k] = complete_features_list[k]+j[k]\n",
    "    \n",
    "    # pickle the data\n",
    "    if pickle:\n",
    "        np.array(complete_features_list).dump(open('data_lstm/x_feature_arima.npy', 'wb'))\n",
    "    return complete_features_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(feat_all_grad_means[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470\n",
      "166\n",
      "304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[156.37173345474025,\n",
       " 62.32149366866028,\n",
       " 1.232999140272644,\n",
       " 5.025814823312249,\n",
       " 5.389884403292671,\n",
       " 14.612273862705484,\n",
       " 36.434891883195824,\n",
       " 3.09237379284704,\n",
       " 2.266874622624454,\n",
       " 19.058937700983474,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(feat_all_stds))\n",
    "print(len(feat_defective_stds))\n",
    "print(len(feat_good_stds))\n",
    "feat_all_stds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting an ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import viets time series\n",
    "time_series_x = np.load('data_lstm/X_raw.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/steve/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd gd "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in time_series_x:\n",
    "    series = np.transpose(i)[9]\n",
    "    # fit model\n",
    "    model = ARIMA(series, order=(1,1,0))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    print(\"gd\",end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(time_series_x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  gd  "
     ]
    }
   ],
   "source": [
    "for i in time_series_x:\n",
    "    series = np.transpose(i)[1]\n",
    "    # fit model\n",
    "    model = ARIMA(series, order=(1,1,0))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    print(\"gd\",end=\"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1,1,0) Works with 1,4,6\n",
    "\n",
    "not 2,3,5,7,8,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot residual errors\n",
    "residuals = DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             ARIMA Model Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                    D.y   No. Observations:                  599\n",
      "Model:                 ARIMA(5, 1, 0)   Log Likelihood                -419.276\n",
      "Method:                       css-mle   S.D. of innovations              0.485\n",
      "Date:                Sun, 29 Sep 2019   AIC                            852.551\n",
      "Time:                        06:47:04   BIC                            883.318\n",
      "Sample:                             1   HQIC                           864.529\n",
      "                                                                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.4761      1.310     -1.127      0.260      -4.044       1.092\n",
      "ar.L1.D.y     -0.4636      0.039    -11.867      0.000      -0.540      -0.387\n",
      "ar.L2.D.y      0.3426      0.040      8.578      0.000       0.264       0.421\n",
      "ar.L3.D.y      0.4112      0.039     10.580      0.000       0.335       0.487\n",
      "ar.L4.D.y      0.4130      0.040     10.323      0.000       0.335       0.491\n",
      "ar.L5.D.y      0.2875      0.039      7.371      0.000       0.211       0.364\n",
      "                                    Roots                                    \n",
      "=============================================================================\n",
      "                  Real          Imaginary           Modulus         Frequency\n",
      "-----------------------------------------------------------------------------\n",
      "AR.1            1.0021           -0.0000j            1.0021           -0.0000\n",
      "AR.2           -1.1935           -0.4866j            1.2889           -0.4384\n",
      "AR.3           -1.1935           +0.4866j            1.2889            0.4384\n",
      "AR.4           -0.0258           -1.4453j            1.4456           -0.2528\n",
      "AR.5           -0.0258           +1.4453j            1.4456            0.2528\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<statsmodels.tsa.arima_model.ARIMAResultsWrapper at 0x7f8d6feb6dd8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.47610677, -0.46359603,  0.34260841,  0.41117322,  0.4129602 ,\n",
       "        0.28746462])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_all_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3a0bb27c539a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mdisp_feature_mean_etc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3a0bb27c539a>\u001b[0m in \u001b[0;36mdisp_feature_mean_etc\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisp_feature_mean_etc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeat_all_means\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeat_all_stds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeat_defective_means\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feat_all_means' is not defined"
     ]
    }
   ],
   "source": [
    "# input is a feature index\n",
    "\n",
    "def disp_feature_mean_etc(i):\n",
    "    fam = [j[i] for j in feat_all_means]\n",
    "    fas = [j[i] for j in feat_all_stds]\n",
    "    fdm = [j[i] for j in feat_defective_means]\n",
    "    fgm = [j[i] for j in feat_good_means]\n",
    "    fds = [j[i] for j in feat_defective_stds]\n",
    "    fgs = [j[i] for j in feat_good_stds]\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "\n",
    "    t=0.8\n",
    "\n",
    "    plt.subplot(431)\n",
    "    plt.plot(np.linspace(0,1,len(fam)), fam,\"x\",alpha=t)\n",
    "    plt.title(\"feat_all_means\")\n",
    "\n",
    "    plt.subplot(432)\n",
    "    plt.plot(np.linspace(0,1,len(fdm)), fdm,\"x\",alpha=t)\n",
    "    plt.title(\"feat_defective_means\")\n",
    "\n",
    "\n",
    "    plt.subplot(433)\n",
    "    plt.plot(np.linspace(0,1,len(fgm)), fgm,\"x\",alpha=t)\n",
    "    plt.title(\"feat_good_means\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(434)\n",
    "    plt.plot(np.linspace(0,1,len(fas)), fas,\"x\",alpha=t)\n",
    "    plt.title(\"feat_all_stds\")\n",
    "\n",
    "\n",
    "    plt.subplot(435)\n",
    "    plt.plot(np.linspace(0,1,len(fds)), fds,\"x\",alpha=t)\n",
    "    plt.title(\"feat_defective_stds\")\n",
    "\n",
    "\n",
    "    plt.subplot(436)\n",
    "    plt.plot(np.linspace(0,1,len(fgs)), fgs,\"x\",alpha=t)\n",
    "    plt.title(\"feat_good_stds\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "disp_feature_mean_etc(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
