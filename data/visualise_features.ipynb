{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting\n",
    "import pandas as pd # data manipulation and analysis\n",
    "import numpy as np # numerical computation\n",
    "import pickle\n",
    "\n",
    "import scipy\n",
    "from scipy.interpolate import spline\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data from pickled files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"partitioned_features.pickle\",\"rb\")\n",
    "feat_all = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"partitioned_features_defective.pickle\",\"rb\")\n",
    "feat_defective = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"partitioned_features_good.pickle\",\"rb\")\n",
    "feat_good = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality check 1 - check if all data in good is labeled w/ 0 and all data w/ defective is labeled w/ 1\n",
    "\n",
    "They passed the test :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in feat_defective:\n",
    "    for pt in test:\n",
    "        label = pt[-2]\n",
    "        if label==0:\n",
    "            print(\"Error\")\n",
    "            print(pt)\n",
    "        elif label!=1:\n",
    "            print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in feat_good:\n",
    "    for pt in test:\n",
    "        label = pt[-2]\n",
    "        if label==1:\n",
    "            print(\"Error\")\n",
    "            print(pt)\n",
    "        elif label!=0:\n",
    "            print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate all the means and statndard deviation\n",
    "\n",
    "The methods below take as input a list of features - this is the data, normalised and chopped. The output is some feature of the time series, for instance it could be the mean, the standard deviation, the max, the min, the norm gradient mean etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfeat_all_means = the_means(feat_all)\\nfeat_defective_means = the_means(feat_defective)\\nfeat_good_means = the_means(feat_good)\\n\\nfeat_all_stds = the_stds(feat_all)\\nfeat_defective_stds = the_means(feat_defective)\\nfeat_good_stds = the_means(feat_good)\\n\\nfeat_all_max = the_max(feat_all)\\nfeat_defective_max = the_max(feat_defective)\\nfeat_good_max = the_max(feat_good)\\n\\nfeat_all_min = the_min(feat_all)\\nfeat_defective_min = the_min(feat_defective)\\nfeat_good_min = the_min(feat_defective)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def the_means(feature_list):\n",
    "    feat_means = []\n",
    "    for i in feature_list:\n",
    "        transposed = np.transpose(i)\n",
    "        means = []\n",
    "        for j in transposed:\n",
    "            means.append(np.mean(j))\n",
    "        feat_means.append(means)\n",
    "    return feat_means\n",
    "\n",
    "def the_stds(feature_list):\n",
    "    feat_stds = []\n",
    "    for i in feature_list:\n",
    "        transposed = np.transpose(i)\n",
    "        stds = []\n",
    "        for j in transposed:\n",
    "            stds.append(np.std(j))\n",
    "        feat_stds.append(stds)\n",
    "    return feat_stds\n",
    "\n",
    "def the_max(feature_list):\n",
    "    feat_max = []\n",
    "    for i in feature_list:\n",
    "        transposed = np.transpose(i)\n",
    "        maxes = []\n",
    "        for j in transposed:\n",
    "            maxes.append(max(j))\n",
    "        feat_max.append(maxes)\n",
    "    return feat_max\n",
    "\n",
    "def the_min(feature_list):\n",
    "    feat_min = []\n",
    "    for i in feature_list:\n",
    "        transposed = np.transpose(i)\n",
    "        mins = []\n",
    "        for j in transposed:\n",
    "            mins.append(min(j))\n",
    "        feat_min.append(mins)\n",
    "        \n",
    "def get_gradient(feature_list):# returns the gradient of everything\n",
    "    feat_grad = []\n",
    "    for i in feature_list:\n",
    "        transposed = np.transpose(i)\n",
    "        # find the gradient at each point\n",
    "        gradients = []\n",
    "        for j in range(len(transposed)):\n",
    "            grad_feat = []\n",
    "            for k in range(len(transposed[j])):\n",
    "                if k>=1:\n",
    "                    grad_feat.append(transposed[j][k]-transposed[j][k-1])\n",
    "            gradients.append(grad_feat)\n",
    "        feat_grad.append(np.transpose(gradients))\n",
    "    return feat_grad\n",
    "        \n",
    "def non_zero_grad_mean45(feature_list):# 2d\n",
    "    feature_grad = get_gradient(feature_list)\n",
    "    non_zero_grad_means = []\n",
    "    for i in feature_grad:\n",
    "        transposed = np.transpose(i)\n",
    "        non_zero_grad = [[],[]]\n",
    "        for j in [4,5]:\n",
    "            for k in range(len(transposed[j])):\n",
    "                if transposed[j][k]!=0:\n",
    "                    non_zero_grad[j-4].append(transposed[j][k])\n",
    "        non_zero_grad_means.append([np.mean(map(abs,non_zero_grad[0])),np.mean(map(abs,non_zero_grad[1]))])\n",
    "    return non_zero_grad_means\n",
    "\n",
    "def gradient_norm_mean(feature_list):\n",
    "    feat_grad = get_gradient(feature_list)\n",
    "        \n",
    "    # we want a gradient (absolute value) mean as a feature\n",
    "    feat_grad = map(abs,feat_grad)\n",
    "    gradient_mean = the_means(feat_grad)\n",
    "    \n",
    "    return gradient_mean\n",
    "\n",
    "def double_derivative_norm_mean(feature_list):# 10 D\n",
    "    double_derivative = get_gradient(get_gradient(feature_list))\n",
    "    \n",
    "    # we want the absolute value mean of the double derivative\n",
    "    double_derivative = map(abs,double_derivative)\n",
    "    double_derivative_mean = the_means(double_derivative)\n",
    "    \n",
    "    return double_derivative_mean\n",
    "\n",
    "# returns the input smoothed\n",
    "#def get_smoothed(feature_list):\n",
    "\n",
    "\n",
    "# something we noticed is that features 4, 5 and 6 are often 50 for many data points in a row, in other\n",
    "# words the gradient is 0 quite alot. We therefore add two new features which are \n",
    "# 1) the number of data points where the gradient is 0 divided by the number of times the gradient is zero\n",
    "# we do this for numbers 4, 5 and 6\n",
    "def grad_new_features(feature_list):\n",
    "    feature_grad = get_gradient(feature_list)\n",
    "    new_features_list = []\n",
    "    for i in feature_grad:\n",
    "        transposed = np.transpose(i)\n",
    "        new_feature = []\n",
    "        for j in [4,5,6]:\n",
    "            count=0\n",
    "            for k in range(len(transposed[j])):\n",
    "                if transposed[j][k]==0: count+=1\n",
    "            try: new_feature.append(count/len(transposed[j]))\n",
    "            except ZeroDivisionError: new_feature.append(count/1)\n",
    "        new_features_list.append(new_feature)\n",
    "    return new_features_list\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#feat_all_grad_means = gradient_mean(feat_all)\n",
    "\n",
    "#feat_all_means = the_means(feat_all)\n",
    "\n",
    "new_features = grad_new_features(feat_all)\n",
    "dd = double_derivative_norm_mean(feat_all)\n",
    "\n",
    "\"\"\"\n",
    "feat_all_means = the_means(feat_all)\n",
    "feat_defective_means = the_means(feat_defective)\n",
    "feat_good_means = the_means(feat_good)\n",
    "\n",
    "feat_all_stds = the_stds(feat_all)\n",
    "feat_defective_stds = the_means(feat_defective)\n",
    "feat_good_stds = the_means(feat_good)\n",
    "\n",
    "feat_all_max = the_max(feat_all)\n",
    "feat_defective_max = the_max(feat_defective)\n",
    "feat_good_max = the_max(feat_good)\n",
    "\n",
    "feat_all_min = the_min(feat_all)\n",
    "feat_defective_min = the_min(feat_defective)\n",
    "feat_good_min = the_min(feat_defective)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6387987012987013, 0.48538961038961037, 0.24918831168831168]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features[400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function takes viet's normalised time series list and returns a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_map(time_series):\n",
    "    # means\n",
    "    feat_means = the_means(time_series)# 10 d\n",
    "    # stds\n",
    "    feat_stds = the_stds(time_series)# 10 d\n",
    "    # maxes\n",
    "    feat_max = the_max(time_series)# 10 d\n",
    "    # min\n",
    "    feat_min = the_min(time_series)# 10 d\n",
    "    # gradient mean\n",
    "    feat_grad = gradient_mean_plus(time_series)# 10 d\n",
    "    # new features from 4,5,6\n",
    "    new_feat1 = grad_new_features(time_series)# 3 d\n",
    "    \n",
    "    # fusing the features\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(feat_all_grad_means[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470\n",
      "166\n",
      "304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[156.37173345474025,\n",
       " 62.32149366866028,\n",
       " 1.232999140272644,\n",
       " 5.025814823312249,\n",
       " 5.389884403292671,\n",
       " 14.612273862705484,\n",
       " 36.434891883195824,\n",
       " 3.09237379284704,\n",
       " 2.266874622624454,\n",
       " 19.058937700983474,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(feat_all_stds))\n",
    "print(len(feat_defective_stds))\n",
    "print(len(feat_good_stds))\n",
    "feat_all_stds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the gradient of each feature\n",
    "We discretize the data, taking the data from Viet's one minuit data I will find the gradient at 15 equidistant points and use these as 15 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_all_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3a0bb27c539a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mdisp_feature_mean_etc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3a0bb27c539a>\u001b[0m in \u001b[0;36mdisp_feature_mean_etc\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisp_feature_mean_etc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeat_all_means\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeat_all_stds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeat_defective_means\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feat_all_means' is not defined"
     ]
    }
   ],
   "source": [
    "# input is a feature index\n",
    "\n",
    "def disp_feature_mean_etc(i):\n",
    "    fam = [j[i] for j in feat_all_means]\n",
    "    fas = [j[i] for j in feat_all_stds]\n",
    "    fdm = [j[i] for j in feat_defective_means]\n",
    "    fgm = [j[i] for j in feat_good_means]\n",
    "    fds = [j[i] for j in feat_defective_stds]\n",
    "    fgs = [j[i] for j in feat_good_stds]\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "\n",
    "    t=0.8\n",
    "\n",
    "    plt.subplot(431)\n",
    "    plt.plot(np.linspace(0,1,len(fam)), fam,\"x\",alpha=t)\n",
    "    plt.title(\"feat_all_means\")\n",
    "\n",
    "    plt.subplot(432)\n",
    "    plt.plot(np.linspace(0,1,len(fdm)), fdm,\"x\",alpha=t)\n",
    "    plt.title(\"feat_defective_means\")\n",
    "\n",
    "\n",
    "    plt.subplot(433)\n",
    "    plt.plot(np.linspace(0,1,len(fgm)), fgm,\"x\",alpha=t)\n",
    "    plt.title(\"feat_good_means\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(434)\n",
    "    plt.plot(np.linspace(0,1,len(fas)), fas,\"x\",alpha=t)\n",
    "    plt.title(\"feat_all_stds\")\n",
    "\n",
    "\n",
    "    plt.subplot(435)\n",
    "    plt.plot(np.linspace(0,1,len(fds)), fds,\"x\",alpha=t)\n",
    "    plt.title(\"feat_defective_stds\")\n",
    "\n",
    "\n",
    "    plt.subplot(436)\n",
    "    plt.plot(np.linspace(0,1,len(fgs)), fgs,\"x\",alpha=t)\n",
    "    plt.title(\"feat_good_stds\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "disp_feature_mean_etc(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
